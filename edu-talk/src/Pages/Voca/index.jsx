import React, { useState, useEffect } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import CongratulationsModal from '../../components/CongratulationModal';
import Confetti from 'react-confetti';
import { useNavigate } from 'react-router-dom';
import { useCookies } from 'react-cookie';
import * as S from './styles';

const words = [
    'ê³ ë“±ì–´',
    'ë‚ ì”¨',
    'í† ë§ˆí† ',
    'ì†Œê¸ˆ',
    'ë‹¨ì–´ì¥',
];

const Voca = () => {
    const [currentWordIndex, setCurrentWordIndex] = useState(0);
    const [learningProgress, setLearningProgress] = useState(0); 
    const [showCompletionModal, setShowCompletionModal] = useState(false);
    const [showPronunciationModal, setShowPronunciationModal] = useState(false);
    const [showConfetti, setShowConfetti] = useState(false);
    const [showPermissionModal, setShowPermissionModal] = useState(false);
    const [showSettingsModal, setShowSettingsModal] = useState(false);
    const [recordings, setRecordings] = useState([]);
    const [mediaRecorder, setMediaRecorder] = useState(null);
    const [audioChunks, setAudioChunks] = useState([]);
    const [isExiting, setIsExiting] = useState(false);
    const [progress, setProgress] = useState(0); 
    const navigate = useNavigate();
    const [cookies] = useCookies(['language']);
    const language = cookies.language || 'English';

    const {
        transcript,
        resetTranscript,
        listening,
        browserSupportsSpeechRecognition
    } = useSpeechRecognition();

    useEffect(() => {
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                const recorder = new MediaRecorder(stream);
                setMediaRecorder(recorder);

                recorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                recorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const url = URL.createObjectURL(audioBlob);

                    setRecordings(prevRecordings => [
                        ...prevRecordings,
                        {
                            word: words[currentWordIndex],
                            url,
                            transcript: "" 
                        }
                    ]);
                    setAudioChunks([]);
                    handleNextWord();
                };
            })
            .catch(error => {
                setShowPermissionModal(true);
            });
    }, [currentWordIndex]);

    useEffect(() => {
        if (!browserSupportsSpeechRecognition) {
            console.error("This browser does not support STT.");
        }
    }, [browserSupportsSpeechRecognition]);

    useEffect(() => {
        setProgress(((learningProgress) / words.length) * 100);
    }, [learningProgress]);

    const handleMicClick = () => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
            SpeechRecognition.stopListening();
        } else {
            resetTranscript();
            setAudioChunks([]);
            SpeechRecognition.startListening({ continuous: true, language: 'ko-KR' });
            mediaRecorder.start();
        }
    };

    useEffect(() => {
        if (transcript !== "") {
            setRecordings(prevRecordings => {
                const lastIndex = prevRecordings.length - 1;
                if (lastIndex >= 0) {
                    const updatedRecordings = [...prevRecordings];
                    updatedRecordings[lastIndex] = {
                        ...updatedRecordings[lastIndex],
                        transcript: transcript
                    };
                    return updatedRecordings;
                }
                return prevRecordings;
            });
        }
    }, [transcript]);

    const speakWord = (word) => {
        const utterance = new SpeechSynthesisUtterance(word);
        utterance.lang = 'ko-KR';
        window.speechSynthesis.speak(utterance);
    };

    useEffect(() => {
        speakWord(words[currentWordIndex]);
    }, [currentWordIndex]);

    const handleNextWord = () => {
        if (currentWordIndex < words.length - 1) {
            setIsExiting(true);
            setTimeout(() => {
                setCurrentWordIndex(currentWordIndex + 1);
                setLearningProgress(learningProgress + 1);
                setIsExiting(false);
            }, 500);
        } else {
            setProgress(100);
            setLearningProgress(5);
            setTimeout(() => {
                triggerCompletion();
            }, 500);
        }
    };

    const triggerCompletion = () => {
        setShowConfetti(true);
        setTimeout(() => {
            setShowCompletionModal(true);
        }, 2000);
    };

    const handleGoMainModal = () => {
        setShowCompletionModal(false);
        setCurrentWordIndex(0);
        setLearningProgress(0);
        setProgress(0);
        setShowConfetti(false);
        navigate('/');
    };

    const handlePronunciationClick = () => {
        setShowPronunciationModal(true);
    };

    const handleCloseModal = () => {
        setShowPronunciationModal(false);
    };

    const handleRefreshPage = () => {
        window.location.reload();
    };

    const handleSettingsClick = () => {
        setShowSettingsModal(true);
    };

    const handleCloseSettingsModal = () => {
        setShowSettingsModal(false);
    };

    const texts = {
        English: {
            settings: 'Settings',
            exit: 'Exit',
            listenAgain: 'Listen Again',
            conversationHistory: 'Conversation History',
            microphonePermission: 'Please enable microphone permission',
            close: 'Close'
        },
        Korean: {
            settings: 'ì„¤ì •',
            exit: 'ë‚˜ê°€ê¸°',
            listenAgain: 'ë‹¤ì‹œ ë“£ê¸°',
            conversationHistory: 'ëŒ€í™” ë‚´ì—­',
            microphonePermission: 'ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì„ ì¼œì£¼ì„¸ìš”',
            close: 'ë‹«ê¸°'
        },
        Japanese: {
            settings: 'è¨­å®š',
            exit: 'é€€å‡º',
            listenAgain: 'ã‚‚ã†ä¸€åº¦èã',
            conversationHistory: 'ä¼šè©±å±¥æ­´',
            microphonePermission: 'ãƒã‚¤ã‚¯ã®ä½¿ç”¨è¨±å¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„',
            close: 'é–‰ã˜ã‚‹'
        }
    };

    return (
        <S.Container>
            <S.TopBar>
                <S.ProgressContainer>
                    <S.ProgressIcon>ğŸ§</S.ProgressIcon>
                    <S.ProgressBar>
                        <S.Progress width={progress} />
                    </S.ProgressBar>
                    <S.ProgressText>{learningProgress}/{words.length}</S.ProgressText>
                </S.ProgressContainer>
                <S.SettingsIcon onClick={handleSettingsClick}>âš™ï¸</S.SettingsIcon>
            </S.TopBar>

            <S.MainContent>
                <S.SpeechBubble isexiting={isExiting ? true : undefined}>
                {words[currentWordIndex]}
                </S.SpeechBubble>
                <S.ControlButton onClick={() => speakWord(words[currentWordIndex])}>
                    {texts[language].listenAgain} ğŸ”Š
                </S.ControlButton>
            </S.MainContent>

            <S.MicrophoneContainer>
                <S.MicrophoneButton onClick={handleMicClick}>
                    {listening ? 'ğŸ›‘' : 'ğŸ¤'}
                </S.MicrophoneButton>
            </S.MicrophoneContainer>

            <S.BottomControls>
                <S.ControlButton onClick={handlePronunciationClick}>
                    <span role="img" aria-label="play">ğŸ”Š</span>
                    <S.ControlText>{texts[language].conversationHistory}</S.ControlText>
                </S.ControlButton>
            </S.BottomControls>

            {showConfetti && (
                <Confetti
                    width={window.innerWidth}
                    height={window.innerHeight}
                    recycle={false}
                    numberOfPieces={500}
                    style={{ position: 'fixed', top: 0, left: 0, zIndex: 1100 }}
                />
            )}

            {showPronunciationModal && (
                <S.ModalOverlay>
                    <S.Modal>
                        <h3>{texts[language].conversationHistory}</h3>
                        <S.ChatContainer>
                            {recordings.map((recording, index) => (
                                <S.ChatMessageContainer key={index}>
                                    <S.UserMessage>
                                        <audio controls>
                                            <source src={recording.url} type="audio/wav" />
                                            Your browser does not support the audio element.
                                        </audio>
                                        <S.TranscriptText>{recording.transcript}</S.TranscriptText>
                                    </S.UserMessage>
                                    <S.ServerMessage>
                                        <p>í”¼ë“œë°± ì˜ì—­ (ì—¬ê¸°ì— ì„œë²„ ì‘ë‹µì´ í‘œì‹œë©ë‹ˆë‹¤)</p>
                                    </S.ServerMessage>
                                </S.ChatMessageContainer>
                            ))}
                        </S.ChatContainer>
                        <S.Button onClick={handleCloseModal}>{texts[language].close}</S.Button>
                    </S.Modal>
                </S.ModalOverlay>
            )}

            {showCompletionModal && <CongratulationsModal goMain={handleGoMainModal} />}

            {showSettingsModal && (
                <S.ModalOverlay>
                    <S.Modal>
                        <S.CloseButton onClick={handleCloseSettingsModal}>Ã—</S.CloseButton>
                        <h3>{texts[language].settings}</h3>
                        <S.Button onClick={() => navigate('/')}>{texts[language].exit}</S.Button>
                    </S.Modal>
                </S.ModalOverlay>
            )}

            {showPermissionModal && (
                <S.ModalOverlay>
                    <S.Modal>
                        <h3>{texts[language].microphonePermission}</h3>
                        <S.Button onClick={handleRefreshPage}>{texts[language].close}</S.Button>
                    </S.Modal>
                </S.ModalOverlay>
            )}
        </S.Container>
    );
};

export default Voca;
